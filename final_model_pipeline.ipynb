{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "2yvnD50yId7R",
    "outputId": "c56bd6fe-0284-49a9-e202-993066a24a4c"
   },
   "outputs": [],
   "source": [
    "# If running in Google Colab, mount drive\n",
    "print('Check if running in Colab...')\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    print('Running in Colab!')\n",
    "    drive.mount('/content/drive')\n",
    "    %cd '/content/drive/My Drive/CIL-FS20'\n",
    "except ImportError:\n",
    "    print('Running locally!')\n",
    "\n",
    "    #Check python version\n",
    "    from platform import python_version\n",
    "    print('Current python version: {}'.format(python_version()))\n",
    "\n",
    "    # Check available GPUs\n",
    "    import tensorflow as tf\n",
    "    no_GPUs_available = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "    print(\"Number of GPUs Available: {}\".format(no_GPUs_available))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IM1egVPi4h-m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.backend import binary_crossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from util.mask_to_submission import masks_to_submission\n",
    "import util.metrics as metrics\n",
    "import util.utility as util\n",
    "import util.post_processing as pp\n",
    "\n",
    "## Install the following packages\n",
    "import imageio\n",
    "import natsort\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYFEgfUVId7_"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXjaqHt_Id8B"
   },
   "outputs": [],
   "source": [
    "# Name of the current model\n",
    "MODEL_NAME = 'final_model'\n",
    "IMG_WIDTH = 608\n",
    "IMG_HEIGHT = 608\n",
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH = 750\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 2          # 8 on Leonhard\n",
    "VALIDATION_SPLIT = 0.1\n",
    "rnd_seed = 4\n",
    "np.random.seed(rnd_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqd81OQ-Id8Q"
   },
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "TgqApFoDId8T",
    "outputId": "45d7cd32-ca06-4b6d-f3e7-504e5ca984b6"
   },
   "outputs": [],
   "source": [
    "logging.info('Loading training and test images')\n",
    "training_image_dir = \"training_images/images/\"\n",
    "training_label_dir = \"training_images/groundtruth/\"\n",
    "test_image_dir = \"test_images/normal/\"\n",
    "rotated_test_image_dir = \"test_images/rotated/\"\n",
    "\n",
    "files_image = os.listdir(training_image_dir)\n",
    "files_image = natsort.natsorted(files_image)\n",
    "files_image_original = files_image[-10:]\n",
    "files_image_extra = files_image[:5]\n",
    "\n",
    "files_label = os.listdir(training_label_dir)\n",
    "files_label = natsort.natsorted(files_label)\n",
    "files_label_original = files_label[-10:]\n",
    "files_label_extra = files_label[:5]\n",
    "\n",
    "files_test = os.listdir(test_image_dir)\n",
    "files_test = natsort.natsorted(files_test)\n",
    "\n",
    "# Load Images and labels\n",
    "training_image_original = util.load_images(training_image_dir, files_image_original, \"RGB\")\n",
    "training_image_extra = util.load_images(training_image_dir, files_image_extra, \"RGB\")\n",
    "training_label_original = util.load_images(training_label_dir, files_label_original, \"L\")\n",
    "training_label_extra = util.load_images(training_label_dir, files_label_extra, \"L\")\n",
    "test_image = pp.prepare_test_images(len(files_test), test_image_dir, files_test, rotated_test_image_dir)\n",
    "\n",
    "print(\"TRAINING:\")\n",
    "print(training_image_original.shape)\n",
    "print(training_label_original.shape)\n",
    "print(training_image_extra.shape)\n",
    "print(training_label_extra.shape)\n",
    "print(\"TEST:\")\n",
    "print(test_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2zzJO7UQId8i"
   },
   "source": [
    "## Preprocess Images\n",
    "- Training images have size 400x400 and test images have size 608x608. So we\n",
    "  need to pad training images to same size, for that we use mirror padding for now.\n",
    "- Get a validation set of untouched original training images.\n",
    "- Augment original training data with vertical and horizontal flips and 45 degrees\n",
    "  rotations.\n",
    "- Also augment validation set to get a better average performance.\n",
    "- Rescale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kXz0LD6uId8k",
    "outputId": "1fddf52a-5c05-4297-d4ff-b2774b8e17fc"
   },
   "outputs": [],
   "source": [
    "# Mirror padd all training images to get same size as test images\n",
    "training_image_original = util.padd_images(training_image_original, 608, 608).astype(np.uint8)\n",
    "training_image_extra = util.padd_images(training_image_extra, 608, 608).astype(np.uint8)\n",
    "training_label_original = util.padd_images(training_label_original, 608, 608).astype(np.uint8)\n",
    "training_label_extra = util.padd_images(training_label_extra, 608, 608).astype(np.uint8)\n",
    "\n",
    "# Create a validation set\n",
    "training_image_original, validation_image, training_label_original, validation_label = train_test_split(\n",
    "    training_image_original, training_label_original, test_size=VALIDATION_SPLIT, random_state=rnd_seed)\n",
    "\n",
    "# Pre-augment original training data to make original dataset\n",
    "# more significant than self generated dataset. Augment validation set, so we need\n",
    "# to sacrifice less training images for validation.\n",
    "# only Augment original Data if running on Leonhard, as it uses a lot of RAM\n",
    "\n",
    "#training_image_original = util.add_flipped_images(training_image_original)\n",
    "#training_label_original = util.add_flipped_images(training_label_original)\n",
    "#validation_image = util.add_flipped_images(validation_image)\n",
    "#validation_label = util.add_flipped_images(validation_label)\n",
    "\n",
    "#training_image_original = util.add_rotated_images(training_image_original)\n",
    "#training_label_original = util.add_rotated_images(training_label_original)\n",
    "#validation_image = util.add_rotated_images(validation_image)\n",
    "#validation_label = util.add_rotated_images(validation_label)\n",
    "\n",
    "training_image = np.concatenate((training_image_original, training_image_extra), axis=0)\n",
    "training_label = np.concatenate((training_label_original, training_label_extra), axis=0)\n",
    "training_label = np.expand_dims(training_label, -1)\n",
    "validation_label = np.expand_dims(validation_label, -1)\n",
    "\n",
    "# Rescale validation images/labels and test images because generator will do the same with training data\n",
    "training_image = training_image.astype(np.float32)/255.0\n",
    "training_label = training_label.astype(np.float32)/255.0\n",
    "validation_image = validation_image.astype(np.float32)/255.0\n",
    "validation_label = validation_label.astype(np.float32)/255.0\n",
    "test_image = test_image.astype(np.float32)/255.0\n",
    "logging.info('Finished Preprocessing!')\n",
    "\n",
    "print(training_image.shape)\n",
    "print(training_label.shape)\n",
    "print(validation_image.shape)\n",
    "print(validation_label.shape)\n",
    "\n",
    "# Plot random Sample of images\n",
    "n = training_image.shape[0]\n",
    "index = random.randint(0, n-1)\n",
    "num_samples = 5\n",
    "\n",
    "f = plt.figure(figsize = (15, 25))\n",
    "for i in range(1, num_samples*2, 2):\n",
    "  index = random.randint(0, n-1)\n",
    "\n",
    "  f.add_subplot(num_samples, 2, i)\n",
    "  plt.imshow(training_image[index])\n",
    "  plt.title(\"Preprocessed Image\")\n",
    "  plt.axis('off')\n",
    "\n",
    "  f.add_subplot(num_samples, 2, i+1)\n",
    "  plt.imshow(np.squeeze(training_label[index]))\n",
    "  plt.title(\"Preprocessed Label\")\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1IIrUHMZId9B"
   },
   "source": [
    "## Keras Datagenerator\n",
    "\n",
    "We use the Keras Data Generator to additionally augment our training set online while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlvQpArBId9E"
   },
   "outputs": [],
   "source": [
    "# We create an instance for the training images, training labels and test images\n",
    "data_gen_args = dict(width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     #zoom_range=0.05,\n",
    "                     #shear_range=0.05,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect')\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_generator = image_datagen.flow(\n",
    "    training_image,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=seed)\n",
    "mask_generator = mask_datagen.flow(\n",
    "    training_label,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=seed)\n",
    "\n",
    "# Combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGj_TtiRId9b"
   },
   "source": [
    "## Model: Fully CNN built in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GpHAHBwaId9d",
    "outputId": "5c9a8f5c-5c07-466b-bd35-2b65c5d1b5ba",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "conv1 = util.convolutional_block(inputs, 16)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = util.convolutional_block(pool1, 32)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = util.convolutional_block(pool2, 64)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = util.convolutional_block(pool3, 128)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = util.convolutional_block(pool4, 256)\n",
    "pool5 = MaxPooling2D(pool_size=(2,2)) (conv5)\n",
    "\n",
    "conv6 = util.convolutional_block(pool5, 512)\n",
    "\n",
    "up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "concat7 = concatenate([up7, conv5])\n",
    "conv7 = util.convolutional_block(concat7, 256)\n",
    "\n",
    "up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "concat8 = concatenate([up8, conv4])\n",
    "conv8 = util.convolutional_block(concat8, 128)\n",
    "\n",
    "up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "concat9 = concatenate([up9, conv3])\n",
    "conv9 = util.convolutional_block(concat9, 64)\n",
    "\n",
    "up10 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv9)\n",
    "concat10 = concatenate([up10, conv2])\n",
    "conv10 = util.convolutional_block(concat10, 32)\n",
    "\n",
    "up11 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv10)\n",
    "concat11 = concatenate([up11, conv1])\n",
    "conv11 = util.convolutional_block(concat11, 16)\n",
    "conv12 = Conv2D(1, (1, 1), activation='sigmoid')(conv11)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=conv12)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Ij639fNId9z"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_jASIloeId92",
    "outputId": "55811fe1-2a89-4249-fa1c-8385b59e81ef"
   },
   "outputs": [],
   "source": [
    "model_path = \"./Models/{}.h5\".format(MODEL_NAME)\n",
    "checkpointer = ModelCheckpoint(model_path,\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "csv_logger = CSVLogger(\"./Logs/{}_log.csv\".format(MODEL_NAME), separator=',', append=False)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=6,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "opt = keras.optimizers.Nadam(lr=LEARNING_RATE)\n",
    "\n",
    "model.compile(\n",
    "      optimizer=opt,\n",
    "      loss=metrics.combined_loss,\n",
    "      metrics=[metrics.iou_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nkz8GKsMId-B"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data =(validation_image, validation_label),\n",
    "                              steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                              epochs=EPOCHS,\n",
    "                              callbacks = [checkpointer, csv_logger, lr_reducer, early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "colab_type": "code",
    "id": "JpBB6gS-Id-N",
    "outputId": "8f5585f2-6ccb-40af-d815-01639887c144"
   },
   "outputs": [],
   "source": [
    "# Show a training report\n",
    "training_info = pd.read_csv('./Logs/{}_log.csv'.format(MODEL_NAME), header=0)\n",
    "\n",
    "acc1, = plt.plot(training_info['epoch'], training_info['iou_coef'])\n",
    "acc2, = plt.plot(training_info['epoch'], training_info['val_iou_coef'])\n",
    "plt.legend([acc1, acc2], ['Training IOU coef', 'Validation IOU coef'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "loss1, = plt.plot(training_info['epoch'], training_info['loss'])\n",
    "loss2, = plt.plot(training_info['epoch'], training_info['val_loss'])\n",
    "plt.legend([acc1, acc2], ['Training Loss', 'Validation Loss'])                            \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0,5)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-GIx9gGId-Z"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "8nc9TbrEId-b",
    "outputId": "141bc3ab-6eb2-4242-b87c-9498b3821ab1"
   },
   "outputs": [],
   "source": [
    "# Kaggle scores on validation images (mean score per image and overall mean score)\n",
    "model = load_model(\"./Models/{}.h5\".format(MODEL_NAME), custom_objects={'combined_loss': metrics.combined_loss, 'iou_coef': metrics.iou_coef})\n",
    "y_pred = model.predict(validation_image, batch_size=4, verbose=1)\n",
    "scores = util.validate_kaggle_score(validation_label, y_pred)\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4G_dMoDqId-n",
    "outputId": "a7f5d628-a49e-4c5c-a34c-b2d1bf7e1c33"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./Models/{}.h5\".format(MODEL_NAME), custom_objects={'combined_loss': metrics.combined_loss, 'iou_coef': metrics.iou_coef})\n",
    "predictions = model.predict(test_image, batch_size=4, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Processing\n",
    "MODE = 'only90_max'\n",
    "RESULT_DIR = './Results/Prediction_Images/{}/'.format(MODEL_NAME)\n",
    "\n",
    "# combine all 8 predicted Images with MODE and save to RESULT_DIR\n",
    "pp.combine_and_save(MODE, RESULT_DIR, predictions, files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vx4m0KKIId-w",
    "outputId": "ddd31c45-d0d9-4cd0-b069-6253c5296a93"
   },
   "outputs": [],
   "source": [
    "# Plot Predictions\n",
    "thresh_val = 0.25\n",
    "predicton_threshold = (predictions > thresh_val).astype(np.uint8)\n",
    "index = random.randint(0, len(predictions)-1)\n",
    "num_samples = 10\n",
    "\n",
    "f = plt.figure(figsize = (15, 25))\n",
    "for i in range(1, num_samples*3, 3):\n",
    "  index = random.randint(0, len(predictions)-1)\n",
    "\n",
    "  f.add_subplot(num_samples, 3, i)\n",
    "  plt.imshow(test_image[index][:,:,0])\n",
    "  plt.title(\"Image\")\n",
    "  plt.axis('off')\n",
    "\n",
    "  f.add_subplot(num_samples, 3, i+1)\n",
    "  plt.imshow(np.squeeze(predictions[index][:,:,0]))\n",
    "  plt.title(\"Prediction\")\n",
    "  plt.axis('off')\n",
    "\n",
    "  f.add_subplot(num_samples, 3, i+2)\n",
    "  plt.imshow(np.squeeze(predicton_threshold[index][:,:,0]))\n",
    "  plt.title(\"Thresholded at {}\".format(thresh_val))\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ScDXHA2-Id-5"
   },
   "source": [
    "## Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "06LmEL7bId-6",
    "outputId": "0a91274b-48f8-4c48-f743-ea49f9a97ba6"
   },
   "outputs": [],
   "source": [
    "result_dir = './Results/Prediction_Images/{}/'.format(MODEL_NAME)\n",
    "submission_filename = './Results/Submissions/{}.csv'.format(MODEL_NAME)\n",
    "util.create_submission(predictions, result_dir, submission_filename, files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_model_pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
